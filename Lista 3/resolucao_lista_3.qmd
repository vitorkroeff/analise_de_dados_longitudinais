---
title: "Resolução da Lista 3 - Análise de Dados Longitudinais"
author: "Helen Lourenço e Vitor Kroeff"
format: pdf
editor: visual
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
require(dplyr)
pacman::p_load(reshape, plyr, ggplot2, gridExtra, mice, geepack, nlme, lme4, Matrix, janitor)
```

# Questão 1

## a) {.smaller}

```{r, warning=FALSE, message=FALSE}
dados <- tibble(foreign::read.dta("toenail.dta"))
ajuste_gee <-geeglm(y ~ trt * month - trt,family = binomial(link = "logit"),
                    data = dados,id = id,corstr = "exchangeable")
```

## b)

```{r, warning=FALSE, message=FALSE}
exp(ajuste_gee$coefficients)

```

O coeficiente $\beta_2$ está relacionado ao efeito do tempo no grupo de tratamento A (ou controle). O expoente $e^{\beta_2}$ representa uma razão de chances. Essa razão de chances indica que, no grupo A, o coeficiente está associado a uma redução na probabilidade de ocorrência de onicólise com o passar dos meses.

## c)

O coefiente $\beta_3$ está associado a interação entre o tratamento B e o tempo em meses. Assim como na alternativa anterior, vemos que $e^{\beta_3} = 0,925$ está assciado a uma reduzação das chances de ocorrência de onicólise com o passar dos meses, porém uma redução menor que a do grupo controle.

## d) {.smaller}

Podemos observar o `summary` do modelo ajustado como sendo:

```{r}
summary(ajuste_gee)
```

Com base no p-valor associado ao $\beta_3$, não parece ter uma diferençã significativa entre os tratamentos aplicados nos Grupos A e B. Também com base nos coeficientes do modelos, podemos observar que essa chance de desnvolver uma onicólise sereve diminui com o passar dos meses.

## e)

```{r}

ajuste_misto <-lme4::glmer(
  formula = y ~ month + trt:month + (1 | id), 
  family = binomial(link = "logit"),         
  data = dados)
```

## f)

Como o efeito aleatório está apenas no intercepto, vimos a seguinte relação aproximada entre entre os coeficientes do modelo marginal e aqueles do modelo de efeitos aleatórios.

$$\beta_M = \frac{\beta_{EA}}{\sqrt{1 + \frac{16\sqrt3}{15 \pi}}\sigma^2_b}$$

```{r, warning=FALSE, message=FALSE, echo=T}
var_bi <- lme4::VarCorr(ajuste_misto)
var_bi

```

```{r, warning=FALSE, message=FALSE, echo=T}
var_bi <- sqrt(as.numeric(var_bi)) # Conversão para númerico
fator <- sqrt(1 + (16*sqrt(3)/(15*pi)*var_bi))
fator
```

Podemos comparar as magnitudes dos efeitos da seguinte forma:

```{r, warning=FALSE, message=FALSE, echo=T}
b.gee <- summary(ajuste_gee)$coef[,1]
b.lme <- summary(ajuste_misto)$coef[,1]
p.gee <- summary(ajuste_gee)$coef[,4]
p.lme <- summary(ajuste_misto)$coef[,4]
round(cbind(b.gee, or.gee = exp(b.gee), p.gee, b.lme, or.lme = exp(b.lme), p.lme,
            razao.b = b.lme/b.gee), 3)

```

Podemos observar estimativas maiores para o modelo misto em relação ao GEE, mas com o mesmo sinal, indicando uma concordância dos efeitos das variáveis.

## g)

```{r, warning=FALSE, message=FALSE, echo=T}
knitr::kable(
exp(summary(ajuste_misto)$coef))
```

A interpretação é muito próxima a do modelo GEE, onde $\beta_2$ está associada a variação no mês no grupo A (controle), porém está sendo levado em conta a variação de cada paciente do grupo A por conta do efeito aleatório no intercepto.

## h)

## i)

## j)

# Questão 2

## a)

```{r, warning=FALSE, message=FALSE, echo=F}
dados_rats <- janitor::clean_names(
    tibble(xlsx::read.xlsx("rats.xlsx", sheetIndex = 1)))
```

```{r, warning=FALSE, message=FALSE, echo=T}

ajuste_gee_ind <- geeglm(response ~ group * time,data = dados_rats,
                         id = subject,corstr = "independence")

ajuste_gee_simetria <- geeglm(response ~ group * time,data = dados_rats,
                         id = subject,corstr = "exchangeable")

ajuste_gee_ar1 <- geeglm(response ~ group * time,data = dados_rats,
                         id = subject,corstr = "ar1")

ajuste_gee_unstructured <- geeglm(response ~ group * time,data = dados_rats,
                         id = subject,corstr = "unstructured")

```

## b)

Nos ajustes realizados na alternativa anterior $Y_{ij}$(`response`) segue uma distribuição Normal com diferentes formas de estimar a matriz de coreelção. Dentre as ajustas estão (em ordem):

-   **Independete***:* Nenhuma correlação entre as observações repetidas.

-   **Simetria Composta***:* Todas as observações dentro de um indivíduo têm a mesma correlação.

-   **AR(1)***:* As observações mais próximas no tempo têm maior correlação.

-   **Não Estruturad***a:* A correlação entre cada par de observações é estimada de forma independente.

## c)

FAZER

## d)

Primeiro podemos observar a estrutura da matriz de correlação da base como um todo e depois de cada grupo. Abaixo temos a matriz de correlação geral da base:

```{r, warning=FALSE, message=FALSE, echo=T}
dados_largo <- reshape::cast(dados_rats, subject ~ time, value = "response")
dados_largo <- na.omit(dados_largo)
round(cor(dados_largo[,2:7]),2)
```

E para os diferentes grupos:

FAZER

# Questão 3

## a)

```{r, warning=FALSE, message=FALSE, echo=T}
ajuste_misto_intercept <- lme4::lmer(response ~ group*time + (1|subject), data = dados_rats) # Intercpto aleatório

ajuste_misto_tempo <- lme4::lmer(response ~ group * time + (1 + time | subject), data = dados_rats) # Intercepto e Tempo aleatório
```

Ambos os modelos ajustado assumem que $ Y_{ij}|b_i\sim N(\mu, \sigma)$ e que os $b_i(b_{0i}, b_{1i}) \sim N(0, \Sigma)$. Onde $b_{0i}$ é o efeito aleatório do intercepto e $b_{1i}$ do tempo.


## b)


